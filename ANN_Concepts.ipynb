{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Concepts.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMONdKEhCMMQH9EUSDd2gbI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sailajarani/ANN/blob/main/ANN_Concepts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd6wMijZ7VSO"
      },
      "source": [
        "## Chain rule\n",
        "$$\n",
        "\\frac{d}{dx}\\left [ f\\left ( g\\left ( x \\right ) \\right ) \\right ] = f \n",
        "′\n",
        " (g(x))g \n",
        "′\n",
        " (x)\n",
        "$$\n",
        "\n",
        "if\n",
        "$$f(x)=\\frac{1}{1+e^{-x}}$$\n",
        "then take $$p=-x ,  q=  1+e^{p}$$\n",
        "\n",
        "then $$f(x)=f\\left ( q  \\left ( p\\left ( x \\right ) \\right )\\right )$$\n",
        "i.e$$f(x) = \\frac{1}{1+e^{p}} = \\frac{1}q{}$$\n",
        "\n",
        "\n",
        "\n",
        "then differentition of f(x)\n",
        "$$\\frac{df}{dx} = \\frac{df}{dq} . \\frac{dq}{dp}.\\frac{dp}{dx}$$\n",
        "\n",
        "$$\\frac{df}{dx}=\\left ( \\frac{-1}{q^{2}} \\right )\\left ( e^{p} \\right )\\left ( -1 \\right )$$\n",
        "$$\n",
        "\\frac{df}{dx}=\\left ( \\frac{-1}{\\left ( 1+e^{-x} \\right )^{2}} \\right )\\left ( e^{-x} \\right )\\left ( -1 \\right )$$\n",
        "if simplify above equation we get following\n",
        "$$\n",
        "\\frac{df}{dx}=f(x)(1-f(x))$$ for  $$f(x)=\\frac{1}{1+e^{-x}}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLyQsWtT7PPf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGWPc4JgBZ-P"
      },
      "source": [
        "## Back Propagation\n",
        "We need to update the weights for the neuron to get error function minimum or zero. That is error function$$e=\\left ( y-{y}' \\right )^{2}$$ need to be zero or mininum.\n",
        "\n",
        "Assume each layer has one neuron and bias to the neuron is zero.\n",
        "\n",
        "Weight update equation is $$\n",
        "w = w-\\eta \\Delta c  =w-\\eta \\left ( \\frac{de}{dw} \\right )$$\n",
        "![Untitled.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xe4CuTyRfTT"
      },
      "source": [
        "From above diagram and equation we need to find $$\\frac{\\partial e}{\\partial w2}$$ for finding weight update.\n",
        "\n",
        "Here e, error function is depend on $$w2$$ because $$e=\\left ( y-a2 \\right )^2$$ where $$y2=a2$$\n",
        "\n",
        "so $e$ is function of $a2 $, i.e  $e=f(a2)$\n",
        "\n",
        "$$a2 = \\sigma (z2)$$\n",
        "\n",
        "so $a2$ is function of $z2 $, i.e  $a2=f(z2)$\n",
        "$$z2=a1.w2$$\n",
        "so $z2$ is function of $w2 $, i.e  $z2=f(w2)$\n",
        "\n",
        "Then $$\\frac{\\partial e}{\\partial w2}=\\frac{\\partial e}{\\partial a2}.\\frac{\\partial a2}{\\partial z2}.\\frac{\\partial z2}{\\partial w2}$$\n",
        "\n",
        "Then $$\\frac{\\partial e}{\\partial w2}=2(y-a2).\\sigma (z2)(1-\\sigma (z2)).a1$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBCbdPaCqfgh"
      },
      "source": [
        "weight updation on output layer is $$w2=w2-\\eta \\frac{\\partial e}{\\partial w2}$$\n",
        "\n",
        "now, we just go back one more step back on diagram then ,error function $e$ depends on $w1$ .\n",
        "\n",
        "we need to update our network $w1$, i.e $$w1=w1-\\eta \\frac{\\partial e}{\\partial w1}$$\n",
        "\n",
        "Then $$\\frac{\\partial e}{\\partial w1}=\\frac{\\partial e}{\\partial a2}.\\frac{\\partial a2}{\\partial z2}.\\frac{\\partial z2}{\\partial a1}.\\frac{\\partial a1}{\\partial z1}.\\frac{\\partial z1}{\\partial w1}$$\n",
        "\n",
        "Then $$\\frac{\\partial e}{\\partial w1}=2(y-a2).\\sigma (z2)(1-\\sigma (z2)).w1.\\sigma (z1)(1-\\sigma (z1)).a0$$\n",
        "\n",
        "until now we are trying to update weights but we consider bias then we have to update bias for getting minimum or no error function.\n",
        "\n",
        "bias update $$b2=b2-\\eta \\frac{\\partial e}{\\partial b2}$$\n",
        "\n",
        "so Then $$\\frac{\\partial e}{\\partial b2}=\\frac{\\partial e}{\\partial a2}.\\frac{\\partial a2}{\\partial z2}.\\frac{\\partial z2}{\\partial b2}$$\n",
        "\n",
        "\n",
        "Then $$\\frac{\\partial e}{\\partial b2}=2(y-a2).\\sigma (z2)(1-\\sigma (z2)).1$$\n",
        "simillarly,\n",
        "$$\\frac{\\partial e}{\\partial b1}=\\frac{\\partial e}{\\partial a2}.\\frac{\\partial a2}{\\partial z2}.\\frac{\\partial z2}{\\partial a1}.\\frac{\\partial a1}{\\partial z1}.\\frac{\\partial z1}{\\partial b1}$$$\n",
        "\n",
        "bias update $$b1=b1-\\eta \\frac{\\partial e}{\\partial b1}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_0lpbdV1uCv"
      },
      "source": [
        "## vanishing gradients\n",
        "if the R.H.S side terms of below equation is less than 1 then product will be very less than zero.\n",
        "i.e\n",
        "$$\\frac{\\partial e}{\\partial w2}=\\frac{\\partial e}{\\partial a2}.\\frac{\\partial a2}{\\partial z2}.\\frac{\\partial z2}{\\partial w2}$$\n",
        "for example \n",
        "\n",
        "$$\\frac{\\partial e}{\\partial w2} = (0.1)(0.2)(0.3)$$\n",
        "$$\\frac{\\partial e}{\\partial w2} = 0.006$$\n",
        "\n",
        "then weight update will be very less\n",
        "$$w2=w2-\\eta \\frac{\\partial e}{\\partial w1}$$\n",
        "$$w2=w2-\\eta (0.006)$$\n",
        "if the network level increses then weight update becomes very  very less. This is nothinng but vanishing gradients.\n",
        "\n",
        "if neural network increses the gradient is becoming vanish.\n",
        "\n",
        "The main disadvantages for this vanishing gradient are\n",
        "1.Lower levels are hard to train\n",
        "2.Training  will be slow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61EWk_O_KiJC"
      },
      "source": [
        "## exploding gradient\n",
        "It is contrast to the vanishing gradients.\n",
        "\n",
        "if the R.H.S side terms of below equation is greater than 1 then product will be very greater than zero.\n",
        "i.e\n",
        "$$\\frac{\\partial e}{\\partial w2}=\\frac{\\partial e}{\\partial a2}.\\frac{\\partial a2}{\\partial z2}.\\frac{\\partial z2}{\\partial w2}$$\n",
        "for example \n",
        "\n",
        "$$\\frac{\\partial e}{\\partial w2} = (10)(20)(30)$$\n",
        "$$\\frac{\\partial e}{\\partial w2} = 6000$$\n",
        "\n",
        "then weight update will be very large\n",
        "$$w2=w2-\\eta \\frac{\\partial e}{\\partial w1}$$\n",
        "$$w2=w2-\\eta (6000)$$\n",
        "if the network level increses then weight update becomes very  very large. This is nothinng but Exploding gradients.\n",
        "\n",
        "if neural network increses the gradient is becoming explode.\n",
        "\n",
        "Disadvantages of explodinng gradients is, solution will be diverge.It mayn't reach gradient minimum. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnffOyteLqmY"
      },
      "source": [
        "## solution for Vanishing gradient and Exploding gradient\n",
        "gradients $\\frac{\\partial e}{\\partial w2}$ depend on activation function $ \\frac{\\partial a2}{\\partial z2}$ and weight intialization $\\frac{\\partial z2}{\\partial w2}$.\n",
        "\n",
        "so,if we choose different activation functions and weight intialization we can control the Vanishing gradient and Exploding gradient.\n",
        "\n",
        "Main solution for this problem is fan-in and fan-outs of neurons are to be same.\n",
        "$$fan_{in} = fan_{out} $$\n",
        "i.e number of inputs is equal to number of outputs of a neuron.\n",
        "And also variance of input and output same$$ \\sigma ^{2}_{in} = \\sigma ^{2}_{out}$$\n",
        "then we can control the vanishing and explode gradients.\n",
        "That means there is proper flow maintain from forward and backward propagation to the neuron then we can control the vanishing and explode gradients issue.\n",
        " \n",
        "But practicle $fan_{in} = fan_{out} $ not always possible.\n",
        "So, we have anther approch to control this issue, i.e\n",
        "For sigmoid function,\n",
        "\n",
        "1.weight intilized with $fan_{avg}  $,$$\n",
        "fan_{avg}=(fan_{in} + fan_{out})/2 $$\n",
        "2.Normal distribution with mean ($\\mu $) = 0 and variance is $(1/fan_{avg})$\n",
        "3.uniform  distribution between -r and r,  where r = $\\sqrt{\\frac{3}{fan_{avg}}}$\n",
        "\n",
        "This uniform disribution is default distribution in keras.\n",
        "The above both uniform and Normal distribution are called Glorot or Xavier distribution.\n",
        "\n",
        "\n",
        "       initialization        activation\n",
        "\n",
        "       Glorot              None,sigmoid,logistic, tanh,softmax\n",
        "\n",
        "       He_normal           ReLu,its varients\n",
        "\n",
        "     Lecun_normal               SELU\n",
        "\n",
        "\n",
        "code:\n",
        "\n",
        "tf.keras.layers.dense(unit,activation=\"activation_name\",kernal_initlizer=\"initlization_name\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyl7lRwrQFli"
      },
      "source": [
        "###speed of updating weights of layers\n",
        "The weights of layers near to ouput layer is updated very faster than remaining layers like next layers in back propagation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEmvLf_4Q94d"
      },
      "source": [
        "## weight initialization effect on weight update\n",
        "1.Case 1: if weight is initialized with high value and activation function ($\\sigma $)is sigmoid then $ \\frac{\\partial \\sigma }{\\partial z}$ becomes zero.\n",
        "$$ \\frac{\\partial \\sigma }{\\partial z}=\\sigma(1-\\sigma)$$\n",
        "for large values of w,$\\sigma$ becomes one. Then $$ \\frac{\\partial \\sigma }{\\partial z}=1(1-1) = 0$$\n",
        "$$\\frac{\\partial e }{\\partial w}= 0\n",
        "$$\n",
        "Then weight update w is not happened because of zero result on error gradient. \n",
        "\n",
        "2.Case 2: if weight is initialized with low value and activation function ($\\sigma $)is sigmoid then $ \\frac{\\partial \\sigma }{\\partial z}$ becomes zero.\n",
        "$$ \\frac{\\partial \\sigma }{\\partial z}=\\sigma(1-\\sigma)$$\n",
        "for large values of w,$\\sigma$ becomes zero. Then $$ \\frac{\\partial \\sigma }{\\partial z}=0(1-0) = 0$$\n",
        "$$\\frac{\\partial e }{\\partial w}= 0\n",
        "$$\n",
        "Then weight update w is not happened because of zero result on error gradient.\n",
        "\n",
        "means , for higher and lower values of weights initialization of neural network  for sigmoid function do not give any proper updations.\n",
        "\n",
        "So, we need check another activation functions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZVrpG3McSNe"
      },
      "source": [
        "## Tanh(z) activation function\n",
        "$$tanh(z)=\\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$$\n",
        "$$\\frac{\\partial tanh(z)}{\\partial z}=1-tanh^{2}(z)$$\n",
        "\n",
        "1.case 1: for weight intilized with high value then $tanh(z)$ becomes one. Then $\\frac{\\partial tanh(z)}{\\partial z}$ becomes (1-1) = 0. That  doesn't show any changes on weight updation because $\\frac{\\partial e}{\\partial w}$ will be zero.\n",
        "\n",
        "2.case 2: for weight intilized with low value then $tanh(z)$ becomes -1. Then $\\frac{\\partial tanh(z)}{\\partial z}$ becomes (1-1) = 0. That  doesn't show any changes on weight updation because $\\frac{\\partial e}{\\partial w}$ will be zero.\n",
        "\n",
        "so we need to choose compromised weight intilization between high and low values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_8OKQ65fnKh"
      },
      "source": [
        "##ReLu(Z) activation function\n",
        "ReLu(z) = z for z$\\geq$0\n",
        "         \n",
        "        = 0 for z < 0\n",
        "ReLu function doesn't have any exponential terms so, it is easy to calculate and less complexity. That maight help to get faster results compared to previous activations.\n",
        "\n",
        "ReLu means Rectified Linear unit.\n",
        "ReLu rectified the function when it is less than zero. so,the name comes Rectified and not only that it is linear or piece wise linear in nature.\n",
        "\n",
        "Coming to weight intialization, if weight(w) is greater than zero and input is 1 then ReLu function becomes (a.w) = (x.w) = (1.w) = w.\n",
        "\n",
        "Then differentiation of Relu w.r.t z becomes$$\\frac{\\partial ReLu(z)}{\\partial z} = 1 , z\\geq 1$$\n",
        "so , \n",
        "$\\frac{\\partial e}{\\partial w}$ has some value other than zero and weight updatation works  i.e $w=w-\\eta \\frac{\\partial e}{\\partial w}$.\n",
        "\n",
        "for weight less than zero, all $\\frac{\\partial ReLu(z)}{\\partial z}$,$\\frac{\\partial e}{\\partial w}$ becomes zero that means no updatation to weight. i.e $w=w-\\eta \\frac{\\partial e}{\\partial w}$,$w=w-\\eta .0$,$w=w$. changed weight w is equal to same as it as previous, i.e no updation.\n",
        "\n",
        "This condition is called Dying ReLu.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT7ipVO6urq2"
      },
      "source": [
        "### Transfer learning\n",
        "Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task.\n",
        "\n",
        "It is a popular approach in deep learning where pre-trained models are used as the starting point on computer vision and natural language processing tasks given the vast compute and time resources required to develop neural network models on these problems and from the huge jumps in skill that they provide on related problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRyka1E6yOuo"
      },
      "source": [
        "### Batch Normalization\n",
        "\n",
        "Model will be slow or may have less accuracy even though we use Transfer learning and activation function. For this situation we can apply anthor method is Batch Normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S54_pWqOwGKR"
      },
      "source": [
        "### Internal covariate shift (ICS)\n",
        "\n",
        "We define Internal Covariate Shift as the change in the distribution of network activations due to the change in network parameters during training.\n",
        "\n",
        "In neural networks, the output of the first layer feeds into the second layer, the output of the second layer feeds into the third, and so on. When the parameters of a layer change, so does the distribution of inputs to subsequent layers.\n",
        "\n",
        "\n",
        "These shifts in input distributions can be problematic for neural networks, especially deep neural networks that could have a large number of layers.\n",
        "\n",
        "\n",
        "Batch normalization is a method intended to mitigate internal covariate shift for neural networks.\n",
        "\n",
        "We need to reduce the ICS to get faster convergence and faster training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF7O5HPVtbSl"
      },
      "source": [
        "### Batch normalization\n",
        "Training deep neural networks with tens of layers is challenging as they can be sensitive to the initial random weights and configuration of the learning algorithm.\n",
        "\n",
        "One possible reason for this difficulty is the distribution of the inputs to layers deep in the network may change after each mini-batch when the weights are updated. This can cause the learning algorithm to forever chase a moving target. This change in the distribution of inputs to layers in the network is referred to the technical name “internal covariate shift.”\n",
        "\n",
        "\n",
        "Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hkOTs4dhSYz"
      },
      "source": [
        "The network converges fastly, when inputs are whitend. Whitend means uniformaly transformed to Zero mean and unit variance.\n",
        "In general deep learning network takes input data in batches not in whole data at a time.\n",
        "\n",
        "Batch normalization, name itself says the data will be taken in batches and normalize the data in each batch and each epoch. Overall the data must be in zero mean and unit variance i.e nothing but normalize the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8yoBNlYqS9S"
      },
      "source": [
        "### Optimizers\n",
        "\n",
        "weight updations observations or draw backs for gradient desent(GD)\n",
        "\n",
        "1.weight updation is directly proportional to $\\frac{\\partial e}{\\partial w}$. Means if slope is high then weight updation is high,when  if slope is low then weight updation is low or slow.\n",
        "\n",
        "2.weight udation is stuck at saddle point even though it didn't reach at local minimum.\n",
        "\n",
        "3.It doesn't remember past updates.\n",
        "\n",
        "4.It  is slow for deep neural networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtweg3qbdDt2"
      },
      "source": [
        "SGD is fater than GD, because in GD data is processed at a time and for that GD cost function is complex for data but for SGD data is processed with single random row or few number of data rows at a time that makes less complexity.\n",
        "\n",
        "SGD is faster than GD.\n",
        "\n",
        "Mini batcher Optimizer is like intermideate of SGD and GD.\n",
        "It can processed the data with mini batches wise.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDP2gWhUfF-6"
      },
      "source": [
        "\n",
        "We are going learn more optimizers to avoid problems of gradient desent(GD).\n",
        "\n",
        "1) Momentum Optimization\n",
        "\n",
        ">For this Momentum optimizer weight updation is $$ w = w-m$$\n",
        "\n",
        ">where m is momentum, $ m =  \\beta m + \\eta \\frac{\\partial c}{\\partial w}$ and $ \\beta$ is coefficient of momentum.\n",
        "\n",
        "In general $ \\beta$ is 0.9.\n",
        "\n",
        ">Advantages\n",
        "\n",
        "  Reduces the oscillations and high variance of the parameters.\n",
        "\n",
        "Converges faster than gradient descent.\n",
        "\n",
        ">Disadvantages\n",
        "\n",
        "One more hyper-parameter is added which needs to be selected manually and accurately.\n",
        "\n",
        "> In Keras\n",
        "\n",
        "optmizer_1 = tf.keras.optimizers.SGD(lr=0.01,momentum=0.9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e6At5pupjuc"
      },
      "source": [
        "### Nesterov Accelerated Gradient(NAG) Optimizer\n",
        "\n",
        "It is also called Nesterov Momentum Optimizer. It is faster than Momentum Optimizer.\n",
        "\n",
        "weight update is as follows$$m=\\beta m+\\frac{\\partial c}{\\partial w}|w=(w-\\beta m)$$\n",
        "\n",
        "$$ w=w-m$$\n",
        "\n",
        "Momentum may be a good method but if the momentum is too high the algorithm may miss the local minima and may continue to rise up.\n",
        "\n",
        "So, to resolve this issue the NAG algorithm was developed.\n",
        "\n",
        "We know we’ll be using $\\beta m$ for modifying the weights so, $(w-\\beta m)$ approximately tells us the future location. Now, we’ll calculate the cost based on this future parameter rather than the current one.\n",
        "\n",
        ">Advantages:\n",
        "Does not miss the local minima.\n",
        "Slows if minima’s are occurring.\n",
        "\n",
        ">Disadvantages:\n",
        "Still, the hyperparameter needs to be selected manually.\n",
        "\n",
        ">In keras \n",
        "optimizer_2 = tf.keras.optimizer.SGD(lr=0.01,momentum=0.9,nestrov=True)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WrKOPpgu3Qs"
      },
      "source": [
        "### Adagrad (Adaptive Gradient) optimizer\n",
        "\n",
        "One of the disadvantages of all the optimizers explained is that the learning rate is constant for all parameters and for each cycle.\n",
        "\n",
        " This optimizer changes the learning rate. It changes the learning rate ‘η’ for each parameter and at every time step ‘t’. \n",
        "\n",
        "\n",
        "weight updation$$s= s+(\\frac{\\partial c}{\\partial w}|w=w )^{2}$$\n",
        "$$ w=w-\\frac{(\\frac{\\partial c}{\\partial w})}{\\sqrt{s+\\varepsilon }}$$\n",
        "\n",
        ">where s is scaling factor\n",
        "\n",
        ">$\\varepsilon$ is smoothing factor for to avoid zero division.\n",
        " $\\varepsilon = 10^{-7}$\n",
        "\n",
        "\n",
        ">Advantage:\n",
        "\n",
        "No need to update the learning rate manually as it changes adaptively with iterations.\n",
        "\n",
        ">Disadvantage:\n",
        "\n",
        "As the number of iteration becomes very large learning rate decreases to a very small number which leads to slow convergence.\n",
        "\n",
        " \n",
        "> In keras\n",
        "\n",
        "tf.keras.optimizers.Adagrad(\n",
        "    learning_rate=0.001, initial_accumulator_value=0.1, epsilon=1e-07,\n",
        "    name='Adagrad', **kwargs\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz4AdRJpmn7I"
      },
      "source": [
        "### RMSprop optimizer\n",
        "\n",
        "RMSprop as well divides the learning rate by an exponentially decaying average of squared gradients. Hinton suggests γ be set to 0.9, while a good default value for the learning rate η is 0.001.\n",
        "\n",
        ">keras\n",
        "tf.keras.optimizer.RMSprop(leaning_rate=0.01,rho=0.9)\n",
        "\n",
        "It is one of the popular optimizer before Adam optimizer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHnHg2Wwn_gD"
      },
      "source": [
        "### Adam optimizer\n",
        "\n",
        "It is adaptive momentum optimizer.\n",
        "\n",
        "Adam can be looked at as a combination of RMSprop and Stochastic Gradient Descent with momentum.\n",
        "\n",
        "Adam computes adaptive learning rates for each parameter. In addition to storing an exponentially decaying average of past squared gradients vt like Adadelta and RMSprop, Adam also keeps an exponentially decaying average of past gradients mt, similar to momentum. Whereas momentum can be seen as a ball running down a slope, Adam behaves like a heavy ball with friction, which thus prefers flat minima in the error surface.\n",
        "\n",
        ">keras\n",
        "tf.keras.optimizer.Adam(learning_rate=0.01,beta_1=0.9,beta_2=0.99)\n",
        "\n",
        "\n",
        ">Advantages:\n",
        "\n",
        "The method is too fast and converges rapidly.\n",
        "Rectifies vanishing learning rate, high variance.\n",
        "\n",
        "\n",
        ">Disadvantages:\n",
        "\n",
        "Computationally costly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKFkw7e4rHev"
      },
      "source": [
        "### which optimizer is good\n",
        "\n",
        "For simple problems we can use SGD,NAG.\n",
        "\n",
        "Best optimizer for now a days use are Adam, RMSProp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muGXUMNus3X2"
      },
      "source": [
        "### Regularization\n",
        "\n",
        "One of the most common problem data science professionals face is to avoid overfitting.\n",
        "\n",
        "Regularization is a technique which makes slight modifications to the learning algorithm such that the model generalizes better.By Regularization we can slove the overfitting problems.\n",
        "\n",
        "In machine learning, you will have a fair idea that regularization penalizes the coefficients. In deep learning, it actually penalizes the weight matrices of the nodes.\n",
        "\n",
        "L1 and L2 are the most common types of regularization. These update the general cost function by adding another term known as the regularization term.\n",
        "\n",
        ">Cost function = Loss (say, binary cross entropy) + Regularization term\n",
        "\n",
        "Due to the addition of this regularization term, the values of weight matrices decrease because it assumes that a neural network with smaller weight matrices leads to simpler models. Therefore, it will also reduce overfitting to quite an extent.\n",
        "\n",
        "In L1, we have:\n",
        "\n",
        "$$new-cost-function = old-cost-function + \\alpha *\\sum W$$\n",
        "\n",
        "In L2, we have:\n",
        "\n",
        "$$new-cost-function = old-cost-function + \\alpha *\\sum (W)^2$$\n",
        "\n",
        ">In keras\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "model.add(Dense(64, input_dim=64,\n",
        "                kernel_regularizer=regularizers.l2(0.01)\n",
        "\n",
        "\n",
        "model.add(Dense(64, input_dim=64,\n",
        "                kernel_regularizer=regularizers.l1(0.1)\n",
        "              \n",
        "\n",
        "model.add(Dense(64, input_dim=64,\n",
        "                kernel_regularizer=regularizers.l1_l2(0.1,0.01)\n",
        "                "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3kK9jvATQRy"
      },
      "source": [
        ">for max regularization\n",
        "\n",
        "RegularizedDense = partial(keras.layers.Dense,\n",
        "                           activation=\"elu\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                           kernel_constraint=keras.constraints.max_norm(1.))\n",
        "                      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpDnprEFTl1B"
      },
      "source": [
        "### Dropout Regularization\n",
        "\n",
        "This is the one of the most interesting types of regularization techniques. It also produces very good results and is consequently the most frequently used regularization technique in the field of deep learning.\n",
        "\n",
        " At every iteration, it randomly selects some nodes and removes them along with all of their incoming and outgoing connections as shown below.\n",
        "\n",
        " So each iteration has a different set of nodes and this results in a different set of outputs. It can also be thought of as an ensemble technique in machine learning.\n",
        "\n",
        "Ensemble models usually perform better than a single model as they capture more randomness. Similarly, dropout also performs better than a normal neural network model.\n",
        "\n",
        "This probability of choosing how many nodes should be dropped is the hyperparameter of the dropout function. As seen in the image above, dropout can be applied to both the hidden layers as well as the input layers\n",
        "\n",
        "\n",
        ">in keras\n",
        "\n",
        "\n",
        "from keras.layers.core import Dropout\n",
        "\n",
        "model = Sequential([\n",
        " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
        " Dropout(0.25),\n",
        "\n",
        "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
        " ])"
      ]
    }
  ]
}